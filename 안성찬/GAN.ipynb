{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a163be2",
   "metadata": {},
   "source": [
    "https://github.com/ndb796/Deep-Learning-Paper-Review-and-Practice/blob/master/code_practices/GAN_for_MNIST_Tutorial.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82fc9019",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transform # 전처리\n",
    "from torchvision.utils import save_image # 이미지 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f4c5a8",
   "metadata": {},
   "source": [
    "### generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f20afad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 노이즈분포의 dimension. norm\n",
    "latent_dim = 100\n",
    "\n",
    "\n",
    "# 생성자(Generator) 클래스 정의\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        # 하나의 블록(block) 정의\n",
    "        # 선형 -> 배치정규화 -> activation leakyrelu\n",
    "        def block(input_dim, output_dim, normalize=True):\n",
    "            layers = [nn.Linear(input_dim, output_dim)]\n",
    "            if normalize:\n",
    "                # 배치 정규화(batch normalization) 수행(차원 동일)\n",
    "                layers.append(nn.BatchNorm1d(output_dim, 0.8))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return layers\n",
    "\n",
    "        # 생성자 모델은 연속적인 여러 개의 블록을 가짐\n",
    "        self.model = nn.Sequential(\n",
    "            *block(latent_dim, 128, normalize=False),\n",
    "            *block(128, 256),\n",
    "            *block(256, 512),\n",
    "            *block(512, 1024),\n",
    "            nn.Linear(1024, 1 * 28 * 28), # data 생성. 1에서 28*28로\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):# 노이즈벡터 z\n",
    "        img = self.model(z)\n",
    "        img = img.view(img.size(0), 1, 28, 28) # reshape\n",
    "        return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457d3477",
   "metadata": {},
   "source": [
    "### discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86aa1d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 판별자(Discriminator) 클래스 정의\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.model = nn.Sequential( # 28*28에서 1로\n",
    "            nn.Linear(1 * 28 * 28, 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid(),#확률값\n",
    "        )\n",
    "\n",
    "    # 이미지에 대한 판별 결과를 반환\n",
    "    def forward(self, img):\n",
    "        flattened = img.view(img.size(0), -1) # img 평탄화\n",
    "        output = self.model(flattened)# 모델학습\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5218873",
   "metadata": {},
   "source": [
    "### MNIST데이터셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "988563cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "transforms_train = transforms.Compose([\n",
    "    transforms.Resize(28), # 28*28\n",
    "    transforms.ToTensor(), # to tensor\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(root=\"./dataset\", train=True, download=True, transform=transforms_train)\n",
    "dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=4) # 배치 128"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd15f75",
   "metadata": {},
   "source": [
    "### 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39bc15c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\201910810\\Anaconda3\\lib\\site-packages\\torch\\cuda\\__init__.py:143: UserWarning: \n",
      "NVIDIA GeForce RTX 3060 with CUDA capability sm_86 is not compatible with the current PyTorch installation.\n",
      "The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_61 sm_70 sm_75 compute_37.\n",
      "If you want to use the NVIDIA GeForce RTX 3060 GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
      "\n",
      "  warnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\n"
     ]
    }
   ],
   "source": [
    "# 생성자(generator)와 판별자(discriminator) 초기화\n",
    "generator = Generator() # 객체 생성\n",
    "discriminator = Discriminator()\n",
    "\n",
    "generator.cuda() # gpu\n",
    "discriminator.cuda()\n",
    "\n",
    "# 손실 함수(loss function)\n",
    "# minGmaxDV(D,G)=Ex∼pdata(x)[logD(x)]+Ez∼pz(z)[log(1−D(G(z))]\n",
    "# −1/n∑(yilog(pi)+(1−yi)log(1−pi))\n",
    "#Binary Cross Entropy\n",
    "adversarial_loss = nn.BCELoss() \n",
    "adversarial_loss.cuda()\n",
    "\n",
    "# 학습률(learning rate) 설정\n",
    "lr = 0.0002\n",
    "\n",
    "# 생성자와 판별자를 위한 최적화 함수\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5b7c8df",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/200] [D loss: 0.504237] [G loss: 0.586473] [Elapsed time: 80.42s]\n",
      "[Epoch 1/200] [D loss: 0.478289] [G loss: 1.539897] [Elapsed time: 84.37s]\n",
      "[Epoch 2/200] [D loss: 0.519869] [G loss: 2.322962] [Elapsed time: 88.35s]\n",
      "[Epoch 3/200] [D loss: 0.291653] [G loss: 1.751317] [Elapsed time: 92.34s]\n",
      "[Epoch 4/200] [D loss: 0.499765] [G loss: 2.972520] [Elapsed time: 96.51s]\n",
      "[Epoch 5/200] [D loss: 0.404335] [G loss: 3.156396] [Elapsed time: 100.60s]\n",
      "[Epoch 6/200] [D loss: 0.264175] [G loss: 2.582276] [Elapsed time: 104.51s]\n",
      "[Epoch 7/200] [D loss: 0.509419] [G loss: 0.584401] [Elapsed time: 108.64s]\n",
      "[Epoch 8/200] [D loss: 0.385757] [G loss: 0.972160] [Elapsed time: 112.86s]\n",
      "[Epoch 9/200] [D loss: 0.257142] [G loss: 1.556078] [Elapsed time: 117.20s]\n",
      "[Epoch 10/200] [D loss: 0.326222] [G loss: 1.458638] [Elapsed time: 121.23s]\n",
      "[Epoch 11/200] [D loss: 0.249318] [G loss: 1.701730] [Elapsed time: 125.14s]\n",
      "[Epoch 12/200] [D loss: 0.232217] [G loss: 1.693194] [Elapsed time: 129.12s]\n",
      "[Epoch 13/200] [D loss: 0.358333] [G loss: 3.856864] [Elapsed time: 133.04s]\n",
      "[Epoch 14/200] [D loss: 0.376209] [G loss: 0.846089] [Elapsed time: 137.11s]\n",
      "[Epoch 15/200] [D loss: 0.746192] [G loss: 5.912459] [Elapsed time: 141.07s]\n",
      "[Epoch 16/200] [D loss: 0.136844] [G loss: 2.949156] [Elapsed time: 145.10s]\n",
      "[Epoch 17/200] [D loss: 0.289937] [G loss: 1.375770] [Elapsed time: 149.03s]\n",
      "[Epoch 18/200] [D loss: 0.338494] [G loss: 0.821631] [Elapsed time: 152.86s]\n",
      "[Epoch 19/200] [D loss: 1.341233] [G loss: 7.584263] [Elapsed time: 156.75s]\n",
      "[Epoch 20/200] [D loss: 0.284368] [G loss: 1.324480] [Elapsed time: 160.92s]\n",
      "[Epoch 21/200] [D loss: 0.098659] [G loss: 3.259464] [Elapsed time: 165.17s]\n",
      "[Epoch 22/200] [D loss: 0.114581] [G loss: 4.590393] [Elapsed time: 169.16s]\n",
      "[Epoch 23/200] [D loss: 0.195476] [G loss: 3.957700] [Elapsed time: 173.11s]\n",
      "[Epoch 24/200] [D loss: 0.202384] [G loss: 2.294795] [Elapsed time: 177.20s]\n",
      "[Epoch 25/200] [D loss: 0.143849] [G loss: 2.314010] [Elapsed time: 181.26s]\n",
      "[Epoch 26/200] [D loss: 0.259467] [G loss: 1.097719] [Elapsed time: 185.31s]\n",
      "[Epoch 27/200] [D loss: 0.111810] [G loss: 2.290848] [Elapsed time: 189.29s]\n",
      "[Epoch 28/200] [D loss: 0.127731] [G loss: 2.320641] [Elapsed time: 193.18s]\n",
      "[Epoch 29/200] [D loss: 0.194096] [G loss: 1.875752] [Elapsed time: 197.10s]\n",
      "[Epoch 30/200] [D loss: 0.990101] [G loss: 9.091681] [Elapsed time: 201.23s]\n",
      "[Epoch 31/200] [D loss: 0.168949] [G loss: 2.270551] [Elapsed time: 205.28s]\n",
      "[Epoch 32/200] [D loss: 0.122865] [G loss: 2.988866] [Elapsed time: 209.50s]\n",
      "[Epoch 33/200] [D loss: 0.119477] [G loss: 2.203864] [Elapsed time: 213.81s]\n",
      "[Epoch 34/200] [D loss: 0.221036] [G loss: 1.923823] [Elapsed time: 218.05s]\n",
      "[Epoch 35/200] [D loss: 0.157408] [G loss: 2.550133] [Elapsed time: 222.33s]\n",
      "[Epoch 36/200] [D loss: 0.290121] [G loss: 3.505712] [Elapsed time: 226.48s]\n",
      "[Epoch 37/200] [D loss: 0.358764] [G loss: 1.122828] [Elapsed time: 230.60s]\n",
      "[Epoch 38/200] [D loss: 0.127662] [G loss: 2.417677] [Elapsed time: 234.56s]\n",
      "[Epoch 39/200] [D loss: 0.210644] [G loss: 1.662512] [Elapsed time: 238.48s]\n",
      "[Epoch 40/200] [D loss: 0.433444] [G loss: 5.177372] [Elapsed time: 242.38s]\n",
      "[Epoch 41/200] [D loss: 0.157523] [G loss: 2.886784] [Elapsed time: 246.30s]\n",
      "[Epoch 42/200] [D loss: 0.258902] [G loss: 3.942096] [Elapsed time: 250.25s]\n",
      "[Epoch 43/200] [D loss: 0.239292] [G loss: 2.455129] [Elapsed time: 254.17s]\n",
      "[Epoch 44/200] [D loss: 0.253290] [G loss: 1.931319] [Elapsed time: 258.02s]\n",
      "[Epoch 45/200] [D loss: 0.162055] [G loss: 3.607505] [Elapsed time: 261.91s]\n",
      "[Epoch 46/200] [D loss: 0.214378] [G loss: 3.197006] [Elapsed time: 265.80s]\n",
      "[Epoch 47/200] [D loss: 0.232493] [G loss: 1.592323] [Elapsed time: 269.70s]\n",
      "[Epoch 48/200] [D loss: 0.373954] [G loss: 0.960970] [Elapsed time: 273.61s]\n",
      "[Epoch 49/200] [D loss: 0.268813] [G loss: 1.839733] [Elapsed time: 277.48s]\n",
      "[Epoch 50/200] [D loss: 0.201963] [G loss: 2.712512] [Elapsed time: 281.34s]\n",
      "[Epoch 51/200] [D loss: 0.202948] [G loss: 2.459183] [Elapsed time: 285.23s]\n",
      "[Epoch 52/200] [D loss: 0.299772] [G loss: 1.566782] [Elapsed time: 289.14s]\n",
      "[Epoch 53/200] [D loss: 0.264857] [G loss: 2.365349] [Elapsed time: 293.03s]\n",
      "[Epoch 54/200] [D loss: 0.341126] [G loss: 1.479277] [Elapsed time: 296.93s]\n",
      "[Epoch 55/200] [D loss: 0.257450] [G loss: 1.677540] [Elapsed time: 300.83s]\n",
      "[Epoch 56/200] [D loss: 0.419260] [G loss: 1.343666] [Elapsed time: 304.70s]\n",
      "[Epoch 57/200] [D loss: 0.576360] [G loss: 0.748726] [Elapsed time: 308.57s]\n",
      "[Epoch 58/200] [D loss: 0.273069] [G loss: 1.375224] [Elapsed time: 312.46s]\n",
      "[Epoch 59/200] [D loss: 0.302325] [G loss: 2.181935] [Elapsed time: 316.39s]\n",
      "[Epoch 60/200] [D loss: 0.339261] [G loss: 1.208882] [Elapsed time: 320.26s]\n",
      "[Epoch 61/200] [D loss: 0.459455] [G loss: 3.407765] [Elapsed time: 324.15s]\n",
      "[Epoch 62/200] [D loss: 0.416119] [G loss: 3.019341] [Elapsed time: 328.00s]\n",
      "[Epoch 63/200] [D loss: 0.270995] [G loss: 2.413679] [Elapsed time: 331.89s]\n",
      "[Epoch 64/200] [D loss: 0.302843] [G loss: 1.714613] [Elapsed time: 335.78s]\n",
      "[Epoch 65/200] [D loss: 0.299986] [G loss: 2.475594] [Elapsed time: 339.69s]\n",
      "[Epoch 66/200] [D loss: 0.380145] [G loss: 0.894863] [Elapsed time: 343.54s]\n",
      "[Epoch 67/200] [D loss: 0.387491] [G loss: 1.137990] [Elapsed time: 347.41s]\n",
      "[Epoch 68/200] [D loss: 0.208778] [G loss: 2.009153] [Elapsed time: 351.32s]\n",
      "[Epoch 69/200] [D loss: 0.243973] [G loss: 1.794073] [Elapsed time: 355.23s]\n",
      "[Epoch 70/200] [D loss: 0.307681] [G loss: 1.783658] [Elapsed time: 359.13s]\n",
      "[Epoch 71/200] [D loss: 0.330486] [G loss: 1.259820] [Elapsed time: 363.01s]\n",
      "[Epoch 72/200] [D loss: 0.241161] [G loss: 1.742955] [Elapsed time: 366.89s]\n",
      "[Epoch 73/200] [D loss: 0.385930] [G loss: 1.201496] [Elapsed time: 370.82s]\n",
      "[Epoch 74/200] [D loss: 0.263633] [G loss: 1.823590] [Elapsed time: 374.71s]\n",
      "[Epoch 75/200] [D loss: 0.287708] [G loss: 1.989465] [Elapsed time: 378.64s]\n",
      "[Epoch 76/200] [D loss: 0.328402] [G loss: 2.390717] [Elapsed time: 382.61s]\n",
      "[Epoch 77/200] [D loss: 0.372933] [G loss: 1.161844] [Elapsed time: 386.45s]\n",
      "[Epoch 78/200] [D loss: 0.247969] [G loss: 1.739601] [Elapsed time: 390.33s]\n",
      "[Epoch 79/200] [D loss: 0.195367] [G loss: 2.045504] [Elapsed time: 394.17s]\n",
      "[Epoch 80/200] [D loss: 0.242700] [G loss: 2.944118] [Elapsed time: 398.12s]\n",
      "[Epoch 81/200] [D loss: 0.293167] [G loss: 2.505021] [Elapsed time: 402.13s]\n",
      "[Epoch 82/200] [D loss: 0.446577] [G loss: 4.290662] [Elapsed time: 406.10s]\n",
      "[Epoch 83/200] [D loss: 0.334195] [G loss: 1.174098] [Elapsed time: 410.04s]\n",
      "[Epoch 84/200] [D loss: 0.240424] [G loss: 2.053726] [Elapsed time: 414.04s]\n",
      "[Epoch 85/200] [D loss: 0.249354] [G loss: 1.584195] [Elapsed time: 418.15s]\n",
      "[Epoch 86/200] [D loss: 0.486494] [G loss: 1.053912] [Elapsed time: 422.16s]\n",
      "[Epoch 87/200] [D loss: 0.322014] [G loss: 1.416615] [Elapsed time: 426.08s]\n",
      "[Epoch 88/200] [D loss: 0.307183] [G loss: 2.500309] [Elapsed time: 429.96s]\n",
      "[Epoch 89/200] [D loss: 0.292178] [G loss: 1.572795] [Elapsed time: 433.84s]\n",
      "[Epoch 90/200] [D loss: 0.245741] [G loss: 1.813378] [Elapsed time: 437.74s]\n",
      "[Epoch 91/200] [D loss: 0.334858] [G loss: 2.302122] [Elapsed time: 441.67s]\n",
      "[Epoch 92/200] [D loss: 0.287516] [G loss: 1.534473] [Elapsed time: 445.60s]\n",
      "[Epoch 93/200] [D loss: 0.293622] [G loss: 3.034608] [Elapsed time: 449.53s]\n",
      "[Epoch 94/200] [D loss: 0.279691] [G loss: 1.922258] [Elapsed time: 453.40s]\n",
      "[Epoch 95/200] [D loss: 0.170347] [G loss: 2.935471] [Elapsed time: 457.26s]\n",
      "[Epoch 96/200] [D loss: 0.218613] [G loss: 3.059471] [Elapsed time: 461.16s]\n",
      "[Epoch 97/200] [D loss: 0.220187] [G loss: 2.028390] [Elapsed time: 465.05s]\n",
      "[Epoch 98/200] [D loss: 0.314892] [G loss: 2.567544] [Elapsed time: 469.00s]\n",
      "[Epoch 99/200] [D loss: 0.423007] [G loss: 4.506055] [Elapsed time: 472.90s]\n",
      "[Epoch 100/200] [D loss: 0.321355] [G loss: 1.200496] [Elapsed time: 476.84s]\n",
      "[Epoch 101/200] [D loss: 0.350465] [G loss: 2.285105] [Elapsed time: 480.80s]\n",
      "[Epoch 102/200] [D loss: 0.239324] [G loss: 2.153939] [Elapsed time: 484.74s]\n",
      "[Epoch 103/200] [D loss: 0.284501] [G loss: 2.012654] [Elapsed time: 488.66s]\n",
      "[Epoch 104/200] [D loss: 0.225898] [G loss: 1.810467] [Elapsed time: 492.58s]\n",
      "[Epoch 105/200] [D loss: 0.263445] [G loss: 2.588872] [Elapsed time: 496.46s]\n",
      "[Epoch 106/200] [D loss: 0.178979] [G loss: 2.671131] [Elapsed time: 500.39s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 107/200] [D loss: 0.236830] [G loss: 2.825078] [Elapsed time: 504.30s]\n",
      "[Epoch 108/200] [D loss: 0.189746] [G loss: 2.422426] [Elapsed time: 508.19s]\n",
      "[Epoch 109/200] [D loss: 0.369671] [G loss: 2.918492] [Elapsed time: 512.11s]\n",
      "[Epoch 110/200] [D loss: 0.208822] [G loss: 2.242269] [Elapsed time: 516.00s]\n",
      "[Epoch 111/200] [D loss: 0.236206] [G loss: 4.544458] [Elapsed time: 519.86s]\n",
      "[Epoch 112/200] [D loss: 0.251843] [G loss: 1.540443] [Elapsed time: 523.73s]\n",
      "[Epoch 113/200] [D loss: 0.230409] [G loss: 1.890902] [Elapsed time: 527.64s]\n",
      "[Epoch 114/200] [D loss: 0.267500] [G loss: 3.570394] [Elapsed time: 531.54s]\n",
      "[Epoch 115/200] [D loss: 0.288242] [G loss: 3.687916] [Elapsed time: 535.46s]\n",
      "[Epoch 116/200] [D loss: 0.267477] [G loss: 2.705262] [Elapsed time: 539.46s]\n",
      "[Epoch 117/200] [D loss: 0.322256] [G loss: 1.706963] [Elapsed time: 543.35s]\n",
      "[Epoch 118/200] [D loss: 0.228646] [G loss: 2.147639] [Elapsed time: 547.26s]\n",
      "[Epoch 119/200] [D loss: 0.228468] [G loss: 2.780736] [Elapsed time: 551.19s]\n",
      "[Epoch 120/200] [D loss: 0.239681] [G loss: 2.665491] [Elapsed time: 555.10s]\n",
      "[Epoch 121/200] [D loss: 0.376953] [G loss: 3.237353] [Elapsed time: 558.97s]\n",
      "[Epoch 122/200] [D loss: 0.179351] [G loss: 1.934740] [Elapsed time: 562.87s]\n",
      "[Epoch 123/200] [D loss: 0.192080] [G loss: 2.564712] [Elapsed time: 566.80s]\n",
      "[Epoch 124/200] [D loss: 0.270865] [G loss: 2.095104] [Elapsed time: 570.71s]\n",
      "[Epoch 125/200] [D loss: 0.210785] [G loss: 3.655771] [Elapsed time: 574.63s]\n",
      "[Epoch 126/200] [D loss: 0.258619] [G loss: 2.388470] [Elapsed time: 578.53s]\n",
      "[Epoch 127/200] [D loss: 0.234777] [G loss: 2.599741] [Elapsed time: 582.43s]\n",
      "[Epoch 128/200] [D loss: 0.215602] [G loss: 2.631566] [Elapsed time: 586.32s]\n",
      "[Epoch 129/200] [D loss: 0.202012] [G loss: 2.261082] [Elapsed time: 590.21s]\n",
      "[Epoch 130/200] [D loss: 0.255959] [G loss: 1.850770] [Elapsed time: 594.12s]\n",
      "[Epoch 131/200] [D loss: 0.212558] [G loss: 2.059542] [Elapsed time: 598.04s]\n",
      "[Epoch 132/200] [D loss: 0.258508] [G loss: 2.365900] [Elapsed time: 601.97s]\n",
      "[Epoch 133/200] [D loss: 0.210489] [G loss: 2.021273] [Elapsed time: 605.87s]\n",
      "[Epoch 134/200] [D loss: 0.227750] [G loss: 2.888008] [Elapsed time: 609.76s]\n",
      "[Epoch 135/200] [D loss: 0.256449] [G loss: 3.221717] [Elapsed time: 613.69s]\n",
      "[Epoch 136/200] [D loss: 0.327859] [G loss: 3.357351] [Elapsed time: 617.64s]\n",
      "[Epoch 137/200] [D loss: 0.250169] [G loss: 2.782220] [Elapsed time: 621.58s]\n",
      "[Epoch 138/200] [D loss: 0.294875] [G loss: 2.977276] [Elapsed time: 625.52s]\n",
      "[Epoch 139/200] [D loss: 0.237179] [G loss: 2.585902] [Elapsed time: 629.42s]\n",
      "[Epoch 140/200] [D loss: 0.251420] [G loss: 2.498582] [Elapsed time: 633.39s]\n",
      "[Epoch 141/200] [D loss: 0.237393] [G loss: 1.590938] [Elapsed time: 637.33s]\n",
      "[Epoch 142/200] [D loss: 0.283267] [G loss: 2.890578] [Elapsed time: 641.29s]\n",
      "[Epoch 143/200] [D loss: 0.235725] [G loss: 2.479058] [Elapsed time: 645.19s]\n",
      "[Epoch 144/200] [D loss: 0.266392] [G loss: 2.189898] [Elapsed time: 649.11s]\n",
      "[Epoch 145/200] [D loss: 0.258434] [G loss: 2.637682] [Elapsed time: 653.01s]\n",
      "[Epoch 146/200] [D loss: 0.264808] [G loss: 2.773278] [Elapsed time: 656.90s]\n",
      "[Epoch 147/200] [D loss: 0.254370] [G loss: 1.690112] [Elapsed time: 660.82s]\n",
      "[Epoch 148/200] [D loss: 0.224283] [G loss: 2.179425] [Elapsed time: 664.72s]\n",
      "[Epoch 149/200] [D loss: 0.282040] [G loss: 2.098018] [Elapsed time: 668.64s]\n",
      "[Epoch 150/200] [D loss: 0.311898] [G loss: 2.665249] [Elapsed time: 672.52s]\n",
      "[Epoch 151/200] [D loss: 0.270278] [G loss: 2.224495] [Elapsed time: 676.40s]\n",
      "[Epoch 152/200] [D loss: 0.186828] [G loss: 2.511840] [Elapsed time: 680.33s]\n",
      "[Epoch 153/200] [D loss: 0.236718] [G loss: 2.455433] [Elapsed time: 684.28s]\n",
      "[Epoch 154/200] [D loss: 0.251209] [G loss: 2.293472] [Elapsed time: 688.16s]\n",
      "[Epoch 155/200] [D loss: 0.248171] [G loss: 3.554650] [Elapsed time: 692.03s]\n",
      "[Epoch 156/200] [D loss: 0.206834] [G loss: 2.265333] [Elapsed time: 695.91s]\n",
      "[Epoch 157/200] [D loss: 0.259668] [G loss: 2.497586] [Elapsed time: 699.85s]\n",
      "[Epoch 158/200] [D loss: 0.267448] [G loss: 1.339770] [Elapsed time: 703.76s]\n",
      "[Epoch 159/200] [D loss: 0.268180] [G loss: 2.288368] [Elapsed time: 707.66s]\n",
      "[Epoch 160/200] [D loss: 0.243377] [G loss: 1.562123] [Elapsed time: 711.53s]\n",
      "[Epoch 161/200] [D loss: 0.243445] [G loss: 1.851656] [Elapsed time: 715.45s]\n",
      "[Epoch 162/200] [D loss: 0.272355] [G loss: 2.450522] [Elapsed time: 719.40s]\n",
      "[Epoch 163/200] [D loss: 0.255672] [G loss: 2.795938] [Elapsed time: 723.43s]\n",
      "[Epoch 164/200] [D loss: 0.233541] [G loss: 1.879576] [Elapsed time: 727.34s]\n",
      "[Epoch 165/200] [D loss: 0.214275] [G loss: 2.321348] [Elapsed time: 731.23s]\n",
      "[Epoch 166/200] [D loss: 0.227066] [G loss: 2.556474] [Elapsed time: 735.12s]\n",
      "[Epoch 167/200] [D loss: 0.310089] [G loss: 2.358626] [Elapsed time: 738.99s]\n",
      "[Epoch 168/200] [D loss: 0.263367] [G loss: 2.159357] [Elapsed time: 742.92s]\n",
      "[Epoch 169/200] [D loss: 0.312676] [G loss: 2.166016] [Elapsed time: 746.86s]\n",
      "[Epoch 170/200] [D loss: 0.257506] [G loss: 1.966167] [Elapsed time: 750.80s]\n",
      "[Epoch 171/200] [D loss: 0.236298] [G loss: 1.858437] [Elapsed time: 754.69s]\n",
      "[Epoch 172/200] [D loss: 0.220167] [G loss: 2.230572] [Elapsed time: 758.57s]\n",
      "[Epoch 173/200] [D loss: 0.257636] [G loss: 2.237543] [Elapsed time: 762.45s]\n",
      "[Epoch 174/200] [D loss: 0.236359] [G loss: 2.789244] [Elapsed time: 766.40s]\n",
      "[Epoch 175/200] [D loss: 0.261732] [G loss: 2.568313] [Elapsed time: 770.32s]\n",
      "[Epoch 176/200] [D loss: 0.196081] [G loss: 3.073355] [Elapsed time: 774.21s]\n",
      "[Epoch 177/200] [D loss: 0.319054] [G loss: 2.218051] [Elapsed time: 778.10s]\n",
      "[Epoch 178/200] [D loss: 0.239770] [G loss: 2.095776] [Elapsed time: 781.96s]\n",
      "[Epoch 179/200] [D loss: 0.247624] [G loss: 1.730387] [Elapsed time: 785.90s]\n",
      "[Epoch 180/200] [D loss: 0.273724] [G loss: 2.610982] [Elapsed time: 789.81s]\n",
      "[Epoch 181/200] [D loss: 0.288290] [G loss: 1.842461] [Elapsed time: 793.71s]\n",
      "[Epoch 182/200] [D loss: 0.234002] [G loss: 2.058927] [Elapsed time: 797.60s]\n",
      "[Epoch 183/200] [D loss: 0.228783] [G loss: 2.294611] [Elapsed time: 801.52s]\n",
      "[Epoch 184/200] [D loss: 0.312623] [G loss: 2.017345] [Elapsed time: 805.43s]\n",
      "[Epoch 185/200] [D loss: 0.212247] [G loss: 2.601118] [Elapsed time: 809.37s]\n",
      "[Epoch 186/200] [D loss: 0.248378] [G loss: 1.766804] [Elapsed time: 813.33s]\n",
      "[Epoch 187/200] [D loss: 0.219844] [G loss: 2.001902] [Elapsed time: 817.26s]\n",
      "[Epoch 188/200] [D loss: 0.271978] [G loss: 2.854149] [Elapsed time: 821.14s]\n",
      "[Epoch 189/200] [D loss: 0.190105] [G loss: 2.023701] [Elapsed time: 825.03s]\n",
      "[Epoch 190/200] [D loss: 0.288512] [G loss: 2.437099] [Elapsed time: 828.94s]\n",
      "[Epoch 191/200] [D loss: 0.231647] [G loss: 2.599059] [Elapsed time: 832.89s]\n",
      "[Epoch 192/200] [D loss: 0.275252] [G loss: 1.595489] [Elapsed time: 836.81s]\n",
      "[Epoch 193/200] [D loss: 0.200113] [G loss: 2.010869] [Elapsed time: 840.69s]\n",
      "[Epoch 194/200] [D loss: 0.175823] [G loss: 2.776862] [Elapsed time: 844.58s]\n",
      "[Epoch 195/200] [D loss: 0.286788] [G loss: 2.566800] [Elapsed time: 848.48s]\n",
      "[Epoch 196/200] [D loss: 0.268278] [G loss: 1.767730] [Elapsed time: 852.43s]\n",
      "[Epoch 197/200] [D loss: 0.289737] [G loss: 1.633474] [Elapsed time: 856.37s]\n",
      "[Epoch 198/200] [D loss: 0.316656] [G loss: 2.610702] [Elapsed time: 860.25s]\n",
      "[Epoch 199/200] [D loss: 0.250693] [G loss: 1.650115] [Elapsed time: 864.28s]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "n_epochs = 200 # 학습의 횟수(epoch) 설정\n",
    "sample_interval = 2000 # 몇 번의 배치(batch)마다 결과를 출력할 것인지 설정\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for i, (imgs, _) in enumerate(dataloader):\n",
    "\n",
    "        # 진짜(real) 이미지와 가짜(fake) 이미지에 대한 정답 레이블 생성\n",
    "        real = torch.cuda.FloatTensor(imgs.size(0), 1).fill_(1.0) # 진짜(real): 1\n",
    "        fake = torch.cuda.FloatTensor(imgs.size(0), 1).fill_(0.0) # 가짜(fake): 0\n",
    "\n",
    "        real_imgs = imgs.cuda()\n",
    "\n",
    "        \"\"\" 생성자(generator)를 학습합니다. \"\"\"\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        # 랜덤 노이즈(noise) 샘플링\n",
    "        z = torch.normal(mean=0, std=1, size=(imgs.shape[0], latent_dim)).cuda()\n",
    "\n",
    "        # 이미지 생성\n",
    "        generated_imgs = generator(z)\n",
    "\n",
    "        # 생성자(generator)의 손실(loss) 값 계산\n",
    "        g_loss = adversarial_loss(discriminator(generated_imgs), real)\n",
    "\n",
    "        # 생성자(generator) 업데이트\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        \"\"\" 판별자(discriminator)를 학습합니다. \"\"\"\n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "        # 판별자(discriminator)의 손실(loss) 값 계산\n",
    "        real_loss = adversarial_loss(discriminator(real_imgs), real)\n",
    "        fake_loss = adversarial_loss(discriminator(generated_imgs.detach()), fake)\n",
    "        d_loss = (real_loss + fake_loss) / 2\n",
    "\n",
    "        # 판별자(discriminator) 업데이트\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        done = epoch * len(dataloader) + i\n",
    "        if done % sample_interval == 0:\n",
    "            # 생성된 이미지 중에서 25개만 선택하여 5 X 5 격자 이미지에 출력\n",
    "            save_image(generated_imgs.data[:25], f\"{done}.png\", nrow=5, normalize=True)\n",
    "\n",
    "    # 하나의 epoch이 끝날 때마다 로그(log) 출력\n",
    "    print(f\"[Epoch {epoch}/{n_epochs}] [D loss: {d_loss.item():.6f}] [G loss: {g_loss.item():.6f}] [Elapsed time: {time.time() - start_time:.2f}s]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c5a1a389",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image('92000.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837ee14f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
